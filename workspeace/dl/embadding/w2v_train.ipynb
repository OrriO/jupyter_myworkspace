{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python383jvsc74a57bd0b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f",
   "display_name": "Python 3.8.3 64-bit (conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# import numpy as np \n",
    "# import pandas as pd\n",
    "# import sklearn\n",
    "# import lightgbm as lgb\n",
    "# import matplotlib.pyplot as plt\n",
    "# from tqdm import tqdm\n",
    "# import seaborn as sns\n",
    "# import gc\n",
    "# from collections import defaultdict  \n",
    "# import math  \n",
    "# # 导入 Word2Vec\n",
    "# from gensim.models import Word2V ec\n",
    "\n",
    "\n",
    "# doc = []\n",
    "# tmp_all = pd.DataFrame()\n",
    "# for c in range(6 + 1):  \n",
    "#     click_train = pd.read_csv(train_path + '/underexpose_train_click-{}.csv'.format(c), header=None,  names=['user_id', 'item_id', 'time'])  \n",
    "#     click_test = pd.read_csv(test_path + '/underexpose_test_click-{}.csv'.format(c), header=None,  names=['user_id', 'item_id', 'time'])  \n",
    "#     tmp = click_train.append(click_test,ignore_index=True).sort_values('time')\n",
    "#     tmp_all = tmp_all.append(tmp,ignore_index=True)\n",
    "#     # 提取用户点击序列，并构成文本\n",
    "# tmp_all.drop_duplicates(inplace=True)\n",
    "# tmp_doc = tmp_all.groupby(['user_id'])['item_id'].agg({list}).reset_index()['list'].values.tolist()\n",
    "# if len(doc)==0 : \n",
    "#     doc =tmp_doc\n",
    "# else:\n",
    "#     doc.extend(tmp_doc)\n",
    "# # 转为字符串型才能进行训练\n",
    "# for i in range(len(doc)):\n",
    "#     doc[i] = [str(x) for x in doc[i]]\n",
    "# embed_size=128\n",
    "# model = Word2Vec(doc, size=embed_size, window=50, min_count=3, sg=1, hs=0,negative = 15,iter=200, seed=2020)\n",
    "\n",
    "# # 训练结果提取\n",
    "# values = set(tmp_all['item_id'].values)\n",
    "# w2v=[]\n",
    "\n",
    "# for v in values:\n",
    "#     try:\n",
    "#         a = [int(v)]\n",
    "#         a.extend(model[str(v)])\n",
    "#         w2v.append(a)\n",
    "#     except:\n",
    "#         pass\n",
    "\n",
    "# out_df = pd.DataFrame(w2v)\n",
    "# out_df.columns = ['item_id'] + ['item_vec'+str(i) for i in range(embed_size)]"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str_1='我从哪里来要到何处去'\n",
    "# str_2='我从何处来要到哪里去'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['the', 'wide', 'road', 'shimmered', 'in', 'the', 'hot', 'sun']"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "sentence='The wide road shimmered in the hot sun'\n",
    "tokens=list(sentence.lower().split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{0: 'the', 1: 'wide', 2: 'road', 3: 'shimmered', 4: 'in', 5: 'hot', 6: 'sun'}"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "# 创建字典表\n",
    "word_dict={}\n",
    "index=0\n",
    "for token in tokens:\n",
    "    if token not in word_dict:\n",
    "        word_dict[token]=index\n",
    "        index+=1\n",
    "# 翻转字典表\n",
    "inverse_vocab={index:token for token,index in word_dict.items()}\n",
    "inverse_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 0, 5, 6]"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "# 对原句进行转换\n",
    "example_sequence=[word_dict[word] for word in tokens]\n",
    "example_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[2, 1],\n",
       " [2, 4],\n",
       " [4, 5],\n",
       " [4, 2],\n",
       " [2, 3],\n",
       " [3, 2],\n",
       " [6, 5],\n",
       " [1, 2],\n",
       " [3, 4],\n",
       " [5, 6],\n",
       " [5, 4],\n",
       " [1, 3],\n",
       " [3, 1],\n",
       " [4, 3]]"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "positive_skip_grams, _=tf.keras.preprocessing.sequence.skipgrams(\n",
    "    example_sequence,\n",
    "    vocabulary_size=7,\n",
    "    window_size=2,\n",
    "    negative_samples=0\n",
    ")\n",
    "positive_skip_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(2, 1): (road, wide)\n(2, 4): (road, in)\n(4, 5): (in, hot)\n(4, 2): (in, road)\n(2, 3): (road, shimmered)\n"
     ]
    }
   ],
   "source": [
    "for target, context in positive_skip_grams[:5]:\n",
    "  print(f\"({target}, {context}): ({inverse_vocab[target]}, {inverse_vocab[context]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "target_word,context_word=positive_skip_grams[0]\n",
    "target_word,context_word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}