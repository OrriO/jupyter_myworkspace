# 推荐系统-关联挖掘算法实战

## 1.基于知识的推荐方法简介	

* ​	基于知识区别于以往基于协同过滤算法，基于知识的推荐更多的是交互式问答的环节，分为基于约束的部分，第二是基于实例的部分，使用基于关联规则方法全是基于知识的推荐。

## 2.关联规则算法引入

* 关联规则-------寻找关联购买商品的关系
* 购物篮分析----一次购买分析-----购买小票数据分析
* 行-----用户购买------事务
* 列-----商品集合------项集
* K项集-----购买商品集合的个数就是几项集

## 3.关联分析问题定义

* 对关联分析问题定义
  * 二元表示
    * 只对用户是否购买关系，买0，不买1
  * 项集
    * 项在项集中出现的次数，K项集
  * 支持度计数
    * 包含项集中的事务的个数
  * 支持度和置信度
    * 支持度=支持度计数/事务个数
    * 置信度=支持度计数/前置项出现次数=====在X发生的条件下X和Y共同发生的概率
  * 为什么需要使用支持度和置信度？
    * 支持度可以用于筛选无意义的规则
      * 筛选掉不被频繁购买的商品
      * 用于频繁项挖掘
    * 置信度可以用于选择关联规则
      * 统计购买过X的用户中同时购买Y的概率
      * 用于规则产生
  * 如何挖掘关联规则？
    * 筛选掉不满足支持度阈值的项集，筛选掉不满足置信度阈值的项集
    * 频繁项集：频繁出现的商品列表
      * 支持度计数，如果支持度计数大于一个阈值，将其设置为频繁项集
      * 支持度：如果支持度阈值达到一个阈值，将其设置为频繁项集
  * ​
    * 通过建立树的方法，通过1项集组合成2项集，通过2项集组合3项集，依次进行组合
    * 树的复杂度带来的是存储和计算的复杂度
    * 两个剪枝原理：
      * 如果一个集合是频繁项集，他的子集一定是频繁项集
      * 如果一个子集是非频繁项集，他的超集一定是非频繁项集
    * ​

## 4.Apriori算法详解

* 频繁项集产生算法


* 算法思想：Apriori算法通过设置最小支持度阈值或最小支持度计数，通过扫描数据库得到候选1项集，通过筛选不满足最小支持度计数的商品得到频繁1项集，依次根据候选K-1项集得到频繁K-1项集，直到得到频繁K项集
* 算法步骤：
  * 1.算法扫描数据库，统计候选1项集中每个项出现的次数，根据设定的最小的支持度阈值筛选掉不满足最小支持度阈值的项得到频繁1项集
  * 2.算法再次扫描数据库，得到候选2项集，筛选掉不符合条件的项，得到频繁2项集，由此类推
  * 3.通过指定算法迭代次数或指定阈值算法结束
* 算法特点：
  * 逐层计算：候选1项集-候选2项集----
  * 产生-测试：拿到候选1项集-----频繁1项集----候选2项集-----频繁2项集
* 算法改进：
  * 减少扫描数据库次数
* 算法应用场景
  * 关联挖掘场景分析--捆绑销售购买

## 5.候选集的产生和剪枝与支持度计数

* 候选集产生和剪枝
  * 蛮力方法--从大量的候选1项集中选择项集的组合
  * F（K-1）*F（1）---通过字典顺序进行排序-----进行组合(避免重复组合)
  * F(k-1)*F(k-1)=F(k)----通过字典排序，拿到相同前置项将后置项进行组合的方式
  * 枚举类型(了解)
  * Hash分桶类型（了解）

## 6.Apriori规则产生

* 根据频繁项集得到规则的子集
* 计算子集的置信度，设定一个置信度阈值，如果小于置信度阈值的筛选掉，选择置信度阈值大于或等于指定置信度阈值的项的集合
* 根据逐层产生规则筛选，规则同上

## 7.Apriori案例补充

* 扫描数据库，根据候选项集得到频繁项集
* 根据频繁项集得到关联规则

## 8.Apriori源码梳理与讲解

* Apriori算法源码
  * 产生频繁项集
    * 参考课件python版本代码
  * 产生关联规则
    * 参考代码

## 9.FP-Growth算法引入

* Apriori算法不足的地方
  * Apriori算法产生和测试的技术，需要产生候选项集，找出符合最小支持度计数的频繁项集
  * 将会在Apriori算法中得到非常多的候选项集
  * Apriori扫描数据库的次数较多
* FP-Growth算法
  * 频繁项-增长算法---依赖于FP结构的树结构
  * 如何构建FP树？
  * 如何从FP树中挖掘频繁项？
  * FP树中产生频繁项集需要扫描几次数据库？

## 10.FP-Growth树表示

* 算法思想：通过扫描数据库拿到候选1项集，得到频繁1项集，根据频繁1项集中各个项出现的次数按照从大到小的顺序进行排列，对原来数据集进行重新排序组合，算法第二次扫描数据库，将所有的已经排好顺序的项依照出现的次序进行构建FP树。
* 算法步骤：
  * 1.通过扫描数据库拿到候选1项集，得到频繁1项集，根据频繁1项集中各个项出现的次数按照从大到小的顺序进行排列，对原来数据集进行重新排序组合
  * 2.算法第二次扫描数据库，将所有的已经排好顺序的项依照出现的次序进行构建FP树。
  * 3.对于出现的次数需要在对应的节点中声明，有一个指针列表连接各个相同的节点

## 11.FP-Growth算法频繁项集产生方法

* 算法步骤：(接上)
  * 4.通过FP树寻找后缀节点的前缀路径，如以e节点作为后缀节点，寻找以e节点的前缀路径，如ea、ec、ebe、ac、ebc等路径
  * 5.在寻找路径的时候需要将后缀节点删除，更新前缀路径上支持度计数，将不满足支持度计数的节点删除掉，将满足条件的称为频繁项集
* 算法总结：
  * 如何构建FP树？
    * 首先，需要将候选1项集中各个项通过扫描数据库得到频繁1项集，并且记录每个一项集出现的频次，根据出现频次的高低对源数据中各个项进行重排序
    * 其次，需要第二次扫描数据库，建立FP树，首先将第一条事务数据读入，在读入第二条，如果各个项在路径中有重复的项需要计数加1，得到FP树
  * FP树中产生频繁项集需要扫描几次数据库？
    * 扫描两次数据库
  * 如何从FP树中挖掘频繁项？
    * 寻找后缀节点的前缀路径，从而得到频繁项集

## 12.FP-Growth算法案例讲解

* 算法扫描两次数据库
* 首先扫描数据库一次，按照候选1项集中满足最小支持度计数的构成频繁1项集，按照频繁1项集中出现的次数对源数据进行重新排序
* 再次扫描数据库，构建FP树
* 最后对FP树进行挖掘频繁项集

## 13.FP-Growth算法源码梳理

- 算法扫描两次数据库
- 首先扫描数据库一次，按照候选1项集中满足最小支持度计数的构成频繁1项集，按照频繁1项集中出现的次数对源数据进行重新排序
- 再次扫描数据库，构建FP树
- 最后对FP树进行挖掘频繁项集
- Jupyter(丘比特)=Java+python+R+Julia(MIT)

## 14.Spark频繁模式挖掘实践

* Spark中提供了FP-Growth算法完成频繁项挖掘和规则生成(PEP)

* 参数：

  * 三个：
  * minsupport最小支持度
  * minconfidence最小置信度
  * numpartitions分区数量

* ```scala
  package cn.apple.BigDataMachineLearningPro

  import org.apache.spark.sql.SparkSession
  import org.apache.spark.ml.fpm.FPGrowth

  /**
    * Created by zhao-chj on 2018/11/13.
    */
  object FPGrowth {
    def main(args: Array[String]): Unit = {
      val spark: SparkSession = SparkSession.builder()
        .appName("SparkMlilb")
        .master("local[2]")
        .getOrCreate()
      spark.sparkContext.setLogLevel("WARN")
      import  spark.implicits._
      val dataset = spark.createDataset(Seq(
        "1 2 5",
        "1 2 3 5",
        "1 2")
      ).map(t => t.split(" ")).toDF("items")

      val fpgrowth = new FPGrowth().setItemsCol("items").setMinSupport(0.5).setMinConfidence(0.6)
      val model = fpgrowth.fit(dataset)

      // Display frequent itemsets.
      model.freqItemsets.show()
      //    antecedent ===> consequent
      // Display generated association rules.
      model.associationRules.show()

      // transform examines the input items against all the association rules and summarize the
      // consequents as prediction
      model.transform(dataset).show()
    }
  }
  ```

## 15.基于Spark的FP-Growth算法项目实战

* 数据来源：从Hive处理后的数据，以\001默认方式进行分割
* 数据处理：
  * 将原始数据中购买的数据提取出来
  * 将购买数据整理成购物篮数据(行--事务、列--项集)
* 算法建模
  * Spark-FPGrowth算法
  * 指定三个参数-最小支持度、最小置信度、分区数-----run方法(mlllib)-----fit方法(ml)
* 算法预测：
  * 得到频繁项集
  * 得到关联规则
  * ml库中提供transform方法将事务中出现的项的集合并且规则的前件中存在的直接给出预测结果

## 16.Mlxtend 库实战Apriori 算法(了解)

* mlxtend库实现了机器学习扩展库
* 关联规则算法
  * Apriori----频繁项挖掘
  * AssosiateRules---规则产生

## 17.频繁项集的关联规则生成(了解)

* Assosociate规则
  * confidence
  * lift
  * leaverage
  * convition