# 推荐系统-用户标签预测算法基础实践

## 1.用户画像概述

* 用户画像给到用户打标签
* 用户画像
* 用户角色
* 用户属性
  * 用户画像和用户角色较为接近，而用户属性使用户的画像中的子集
* 用户画像阶段
  * 1.用户画像基础
  * 2.用户画像指标体系
  * 3.标签数据存储方式
  * 4.标签数据开发
  * 5.性能优化及作业调度
  * 6.用户画像应用及优化
* 用户画像基础场景用
  * 搜索领域
  * 个性化推荐领域
  * 其他领域

## 2.常见用户画像业务分析指标

* 以电商为例展开
  * 电商总总体运营指标
  * 网站流浪指标
  * 网站销售指标
  * 客户价值类指标
  * 商品类指标
  * 市场竞争类的指标
  * ​

## 3.如何利用用户行为数据

* 用户的静态数据--mysql
* 用户的动态数据--浏览、加购、收藏等
* 标签形态及标签建模
  * 标签
  * 权重---时间衰减因子，地点因子，是购购买
* 算法路线及算法思路：
  * 用户画像+推荐系统===利用机器学习
* 标签层级
  * 用户+商品+环境
* 属性的县隐性反馈
##4.如何利用用户标签数据

- 当有了标签之后如何使用？
- 在页面中设置依稀标签选项
- 如何推荐标签？
  - 基于物品的热门商品推荐
  - 基于当前浏览物品的热门商品推荐
  - 基于内容的相似度推荐(经常使用标签)

## 5.用户画像建模分类

* 如何对用户画像建模？
  * 定性
  * 定量建立模型
* 用户画像打的哪几类标签：？
  * 统计类标签-pv
  * 规则类标签-近30天活跃度(规则)
  * 挖掘类(机器学习算法构建)

## 6.决策树引入

* 决策树----类似树的概念
* 树---现实生活中树结构--树根--树干---树枝---树叶
* 数据结构中树：根节点---分支节点-----叶子结点
* 机器学习中的 树：分支节点----叶子节点
* 分支节点：特征充当
* 叶子节点：类别标签列的取值

## 7.电商实例引入详解

* 通过对数据集的简单描述强化数据集的构成
* 基于规则建树
* 规则？按照特征的顺序，构建决策树
* 首先选择年龄、收入、学生、信誉依次构建决策树
* 根据决策树可以对部分节点进行剪枝，决策树变得更加简单
* 根据决策树回答业务决策问题
  * 根据已有的特征对决策树进行分类
  * 如果中年人直接推荐商品(给业务人员决策)

## 8.构建决策树三要素

* 特征选择：如何选择特征？依靠信息熵、信息增益、 信息增益率等进行特征选择
* 决策树生成：决策树生成依赖于特征选择，信息增益组成ID3算法，信息增益率C4.5算法，Gini系数Cart树算法
* 决策树剪枝：先剪枝(树生产之前或过程中进行剪枝)和后剪枝(树生长完成之后进行剪枝)

## 9.熵和信息熵详解

* 熵：物理学上，用于能量的分布的均匀性
* 信息熵：信息论上，用于消除信息的不确定性
* 信息熵：首先定义一个不确定性函数，对不确定性函数求解期望，期望就是E(x)=-sum(xlog(x))
* 信息熵越大，信息的不确定性越大，信息的确定性越小，信息的纯度越低
* 信息熵越小，信息的不确定性越小，信息的确定性越大，信息的纯度越高
* 如果用于决策树的分支，优先选择信息熵小的值作为分支节点，构建决策树。
* 概念学习系统使用信息熵

## 10.信息增益与ID3算法详解

* 信息增益：
* 以A节点作为分支节点的信息增益=总体的信息熵-以A节点作为分支节点的信息熵
* 信息增益越大，信息熵越小，信息的不确定性越小，信息的确定性越大，信息的纯度越高
* 信息增益越小，信息熵越大，信息的不确定性越大，信息的确定性越小，信息的纯度越低
* 优先选择信息增益较大的特征作为分支节点
* ID3算法：
  * 输入：样本的集合，属性的集合
  * 输出：决策树
  * 算法步骤：
    * 1.如果所有的属性都处理完毕，直接返回，否则继续下一步
    * 2.计算所有的特征的信息增益，选择信息增益较大的值对应的特征作为分支节点
    * 3.从剩余的属性中选择次信息增益较大的值对应的特征继续分类，直到满足停止条件，递归构建决策
  * 算法停止迭代的条件：
    * 如果样本均分类，就停止迭代
    * 如果没有属性被用于进一步划分，停止迭代
    * 如果达到指定的迭代次数，停止迭代
    * 如果达到设定的树的深度，停止迭代
    * 如果叶子节点包含的样本个数达到指定阈值，也停止迭代
    * 如果分支节点包含的样本个数达到指定的阈值，也停止迭代
    * 如果最大不纯度下降小于a的时候，停止迭代
* 电商购买数据集案例：
  * Gain(age)=info(D)-info(age)

## 11.决策树其他优化算法

* C4.5算法---使用信息增益率--在信息的增益基础上增加了信息熵作为分母进行对比
* Cart树算法---分类和回归算法-----Gini系数
* 贪心算法

## 12.树剪枝详解

* 先剪枝(较多)
  * 在树的生长过程中进行剪枝
    * 如果没有属性被用于进一步划分，停止迭代
    * 如果达到指定的迭代次数，停止迭代
    * 如果达到设定的树的深度，停止迭代
    * 如果叶子节点包含的样本个数达到指定阈值，也停止迭代
    * 如果分支节点包含的样本个数达到指定的阈值，也停止迭代
    * 如果最大不纯度下降小于a的时候，停止迭代
* 后剪枝
  * 在决策树生长完成后进行剪枝
  * 利用MEP最小错误率剪枝技术进行剪枝
    * 利用叶子结点替换子树
    * 利用分支中常出现的子树替换原子树
* 剪枝系数(了解)
  * 定义决策树的损失函数
    * C（x）=SUM(Ni*H(x))
  * a剪枝系数，剪枝系数越小越好，选择不同的a

## 13.电商案例ID3算法实例详解

* 电商数据集1024样本，每个特征具体取值的概率清楚
* 求解特征的信息增益=总体信息熵-以划分节点作为分支节点的信息熵
* 求解最大的信息增益值，作为分支节点，依次选择最大的信息增益值
* 比之前绘制的基于规则建树，简化了许多
* 决策树算法能够选择最重要的特征---------信息增益

## 14.决策树解决电商数据预测购买及补充问题

* 通过skleran实战
* 数据准备
* 数据处理
* 数据切分
* 准备算法
* 训练模型
* 模型预测
* 模型校验
* 模型保存
* 模型决策树可视化---export-graphviz

## 15.决策树实战相亲数据集案例及可视化实战

* 将准备好的相亲数据集通过pandas进行处理
* 准备X和Y特征和标签数据
* 训练模型
* 预测模型
* 校验--可视化

## 16.决策树实战Iris数据集识别及可视化实战

* iris数据集来源于sklearn自带的数据集
* 根据自带的属性完成定义

## 17.决策树算法API详解

* 参数：使用那种算法，最大深度、树的叶子节点个数等
* 属性：features_importance_
* 方法:fit\predict\predict_log_porba\predict_proba

## 18.Python源码的ID3实现简介

## 19.总结

