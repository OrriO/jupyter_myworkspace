# Default system properties included when running spark-submit.
# This is useful for setting default environmental settings.

# Example:
# spark.master                     spark://master:7077
# spark.eventLog.enabled           true
# spark.eventLog.dir               hdfs://namenode:8021/directory
# spark.serializer                 org.apache.spark.serializer.KryoSerializer
# spark.driver.memory              40g
# spark.executor.memory            30g
# spark.executor.extraJavaOptions  -XX:+PrintGCDetails -Dkey=value -Dnumbers="one two three"
spark.serializer                 org.apache.spark.serializer.KryoSerializer
spark.executor.extraLibraryPath  /software/servers/hadoop-2.7.1/lib/native:/software/servers/hadoop-2.7.1/share/hadoop/common/lib/hadoop-lzo-0.4.15.jar
spark.executor.extraJavaOptions  -verbose:gc -XX:+UseCompressedOops -XX:-PrintGCDetails -XX:+PrintGCTimeStamps -XX:CMSInitiatingOccupancyFraction=60 -XX:MaxPermSize=2G
spark.driver.extraJavaOptions -XX:PermSize=128M -XX:MaxPermSize=2G
spark.master                      local
spark.yarn.archive                hdfs://ns2/user/mart_risk/jrdm/lib/spark-2.1.0-hadoop-2.7.1.zip
spark.driver.extraLibraryPath    /software/servers/hadoop-2.7.1/lib/native
spark.eventLog.dir              hdfs://ns2/user/spark/log
spark.history.fs.logDirectory   hdfs://ns2/user/spark/log
#spark.broadcast.factory          org.apache.spark.broadcast.HttpBroadcastFactory
spark.kryoserializer.buffer.max.mb 1024
spark.default.parallelism  50
spark.shuffle.manager            sort
spark.shuffle.maxMergeFactor 80
spark.shuffle.sort.bypassMergeThreshold 200
spark.shuffle.compress true
spark.shuffle.service.enabled false
spark.shuffle.spill true
spark.shuffle.spill.compress true
#spark.shuffle.memoryFraction 0.3
#spark.storage.memoryFraction 0.5
spark.shuffle.consolidateFiles true

spark.file.transferTo false
spark.ui.port 0

spark.network.timeout 20000s
spark.akka.askTimeout 20000s
spark.rpc.timeout 20000s
spark.akka.frameSize 256

#spark.speculation true
#spark.speculation.quantile 0.85

spark.dynamicAllocation.enabled false
#spark.dynamicAllocation.minExecutors 40
#spark.dynamicAllocation.maxExecutors 500
#spark.dynamicAllocation.executorIdleTimeout 60

#spark.sql.planner.sortMergeJoin true
#spark.sql.shuffle.partitions 210
#spark.yarn.executor.memoryOverhead 4096
#spark.scheduler.executorTaskBlacklistTime 30000
spark.task.maxFailures 10

#spark.rdd.compress true
spark.broadcast.compress true


#====================  spark.sql  ====================#
spark.sql.inMemoryColumnarStorage.compressed true
spark.sql.inMemoryColumnarStorage.batchSize 1000000
spark.sql.autoBroadcastJoinThreshold 104857600
spark.sql.tungsten.enabled true
spark.sql.shuffle.partitions 50
spark.sql.planner.externalSort false
